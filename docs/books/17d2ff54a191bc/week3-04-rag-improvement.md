---
title: "RAGの精度を高める：検索品質の改善テクニック"
---

## 「検索の質」が「回答の質」を決める

<!--
この章で扱う内容：
- RAGの品質ボトルネックは多くの場合「検索」にある
- LLMは与えられたコンテキストに基づいて回答するため、検索が悪ければ回答も悪い
- Week 2で作ったRAGの改善余地を考える
-->

## チャンク戦略の見直し

<!--
この章で扱う内容：
- chunk_sizeとchunk_overlapの影響
- 小さすぎるチャンク：文脈が失われる
- 大きすぎるチャンク：ノイズが混入する
- セマンティックチャンキングの考え方（文や段落単位での分割）
- 実験：異なるチャンクサイズでの検索結果比較
-->

## Metadata Filtering：検索をより賢く

<!--
この章で扱う内容：
- メタデータとは何か（ドキュメントの属性情報）
- ChromaDBでのメタデータ付与方法
- フィルタリングによる検索精度向上
- 実装例：ドキュメントにカテゴリやソースを付与
-->

## 実践：Metadata Filteringの実装

<!--
この章で扱う内容：
- knowledge.txtを複数ドキュメントに分割
- 各ドキュメントにメタデータを付与（source, category, date等）
- 検索時にフィルタを適用
- server.pyの修正
-->

## Rerankingの考え方

<!--
この章で扱う内容：
- 初期検索（Retriever）の限界
- Rerankingとは：検索結果を「関連性」で並べ替える
- Cross-Encoderの仕組み（軽く触れる程度）
- Cohere Rerankなどのサービス紹介
- ※本章では概念紹介にとどめ、実装は発展課題とする
-->

## 評価データセットでRAG改善を測定する

<!--
この章で扱う内容：
- 第7章で作成した評価データセットの活用
- 改善前後の回答品質比較
- Langfuseでの可視化
- 「改善」を数値で示すことの重要性
-->

## まとめ

<!--
まとめのポイント：
1. RAGの品質改善は「検索の改善」から始まる
2. チャンク戦略、Metadata Filtering、Rerankingが主な改善手法
3. 改善は必ず評価データセットで効果を測定する
-->

Week 3、お疲れ様でした。これであなたは、LLMアプリケーションを「観測し、評価し、安全に保ち、継続的に改善する」ための基盤を手に入れました。

次のWeek 4では、いよいよこのアプリケーションを**クラウドにデプロイ**し、シンプルなUIと接続します。あなたのAIチャットボットが、ついに世界に公開される瞬間です。

## 本章のソースコード

本章で作成したコードは、以下のGitHubブランチで確認できます。

*   [feature/week3-04-rag-improvement](https://github.com/duotaro/my-ai-bot/tree/feature/week3-04-rag-improvement)
