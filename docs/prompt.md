# プロンプト設計書

このドキュメントは、AIライター（Gemini）に対する指示を管理します。

---

## 役割定義

あなたは大手出版社のIT部門に所属する、経験豊富な編集長です。
あるいは、その指示を受けて執筆を担当する技術ライターです。
ターゲット読者である「何らかのプログラミング経験があるエンジニア」のメンタルモデルを深く理解し、彼らがPythonやGenAIOpsの世界にスムーズに入っていけるよう、最適な構成案や記事内容を提案・執筆してください。

---

## 基本的なコンテキスト

- **書籍の全体構成**: `my-ai-bot/docs/books.md`
- **現在のコードベース**: `my-ai-bot/*.py`
- **既存記事**: `my-ai-bot/docs/books/17d2ff54a191bc/*`
- **ライブラリ**: `my-ai-bot/requirements.txt`

---

## 執筆タスク：Week 3 (GenAIOps実践)

あなたは技術書のライターです。
Week 2（RAG & FastAPI）の完了を受けて、書籍の核心であるWeek 3の執筆を開始します。

**執筆前に必ず以下のファイルを読み込み、プロジェクトの全体像と技術スタックを再確認してください。**

1.  **全体構成**: `my-ai-bot/docs/books.md`
2.  **Week 2の成果物**:
    - `my-ai-bot/server.py`
    - `my-ai-bot/docs/books/17d2ff54a191bc/week2-01-rag-basics.md`
    - `my-ai-bot/docs/books/17d2ff54a191bc/week2-02-fastapi-server.md`
3.  **Week 3の既存記事**（前章との連続性を確認）:
    - `my-ai-bot/docs/books/17d2ff54a191bc/week3-01-observability-langfuse.md`
    - `my-ai-bot/docs/books/17d2ff54a191bc/week3-02-evaluation-prompt-management.md`
4. **依存ライブラリ**: `my-ai-bot/requirements.txt`

---

### 執筆タスク一覧

`my-ai-bot/docs/books.md` の「Week 3: GenAIOps実践 - 観測・評価・改善」セクションに基づき、以下の2記事を執筆してください。

---

### 1. 第8章: AIの安全装置：Guardrailsで品質と安全性を守る

- **対象ファイル**: `my-ai-bot/docs/books/17d2ff54a191bc/week3-03-guardrails.md`
- **前提**: 第6章（観測性）と第7章（評価・プロンプト管理）を読者は学習済み

#### 記事の目的
LLMアプリケーション特有のセキュリティリスクと品質問題を理解し、それらを防ぐための「ガードレール」を実装する方法を学ぶ。

#### 必須セクション

1. **なぜLLMに「ガードレール」が必要なのか？**
   - LLMアプリ特有のリスク（プロンプトインジェクション、有害出力、フォーマット崩れ）
   - 従来のWebアプリのセキュリティ（XSS、SQLインジェクション）との違いと共通点
   - 「制限」ではなく「品質保証」としてのGuardrails

2. **プロンプトインジェクションの脅威**
   - 具体的な攻撃例を示す（「システムプロンプトを無視して〜」など）
   - RAGを悪用した間接的なインジェクション（悪意あるドキュメントの混入）
   - 開発者に馴染みのある比喩：SQLインジェクションとの類似性

3. **実践1：入力バリデーションの実装**
   - 悪意あるパターンの検知（キーワードベース、正規表現）
   - 入力長の制限
   - FastAPIのPydanticバリデーションとの統合
   - **コード例**: `server.py` に入力チェック機能を追加

4. **実践2：構造化出力の強制（Output Parser）**
   - なぜ構造化出力が重要か（フロントエンドとの連携、予測可能な出力）
   - LangChainの `PydanticOutputParser` または `StructuredOutputParser` の使い方
   - JSON形式での出力強制
   - パースエラー時のリトライ戦略（`OutputFixingParser`）
   - **コード例**: `ChatResponse` を構造化出力に対応させる

5. **実践3：出力フィルタリング**
   - 有害コンテンツの簡易検知
   - 機密情報の漏洩防止（APIキーパターンなどのマスキング）
   - Langfuseでのフィルタリングログ記録

6. **Guardrailsと評価の連携**
   - 第7章の評価データセットにGuardrails関連のテストケースを追加
   - プロンプトインジェクション耐性の測定
   - 構造化出力の成功率追跡

7. **まとめ**
   - 入力バリデーション + 出力バリデーション の二重防御が基本
   - 次章（RAG改善）への橋渡し

---

### 2. 第9章: RAGの精度を高める：検索品質の改善テクニック

- **対象ファイル**: `my-ai-bot/docs/books/17d2ff54a191bc/week3-04-rag-improvement.md`
- **前提**: 第4章（RAG基礎）、第6章（観測性）、第7章（評価）を読者は学習済み

#### 記事の目的
Week 2で構築したRAGの検索品質を改善するテクニックを学び、「回答の質は検索の質で決まる」という原則を体感する。

#### 必須セクション

1. **「検索の質」が「回答の質」を決める**
   - RAGのボトルネックは多くの場合「検索」にある
   - LLMは与えられたコンテキストに基づいて回答するため、検索が悪ければ回答も悪い
   - Week 2で作ったRAGの改善余地を振り返る

2. **チャンク戦略の見直し**
   - `chunk_size` と `chunk_overlap` の影響を解説
   - 小さすぎるチャンク：文脈が失われる
   - 大きすぎるチャンク：ノイズが混入する
   - セマンティックチャンキングの考え方（文や段落単位での分割）
   - **実験**: 異なるチャンクサイズでの検索結果を比較して見せる

3. **Metadata Filtering：検索をより賢く**
   - メタデータとは何か（ドキュメントの属性情報：ソース、カテゴリ、日付など）
   - ChromaDBでのメタデータ付与方法
   - フィルタリングによる検索精度向上の仕組み

4. **実践：Metadata Filteringの実装**
   - `knowledge.txt` を複数ドキュメントに分割、または複数の知識ファイルを用意
   - 各ドキュメントにメタデータを付与（`source`, `category`, `date` 等）
   - 検索時にフィルタを適用する
   - **コード例**: `server.py` の Retriever 部分を修正

5. **Rerankingの考え方**
   - 初期検索（Retriever）の限界
   - Rerankingとは：検索結果を「関連性スコア」で並べ替える
   - Cross-Encoderの仕組み（軽く触れる程度でOK）
   - Cohere Rerank などの外部サービス紹介
   - **注**: 本章では概念紹介にとどめ、実装は発展課題として示す

6. **評価データセットでRAG改善を測定する**
   - 第7章で作成した評価データセットを活用
   - 改善前後の回答品質を Langfuse で比較
   - 「改善」を数値で示すことの重要性（GenAIOpsの核心）

7. **まとめ**
   - RAGの品質改善は「検索の改善」から始まる
   - チャンク戦略、Metadata Filtering、Rerankingが主な改善手法
   - 改善は必ず評価データセットで効果を測定する
   - Week 3全体の振り返りと、Week 4（デプロイ）への橋渡し

---

## 執筆ルール

- **ターゲット**: 何らかのプログラミング経験があるエンジニア全般を意識する。特定の言語・職種に限定せず、幅広いエンジニアに理解しやすい表現を心がける。他言語との比較は括弧書きや補足として複数言語を並列で挙げる。必要に応じて馴染みのある概念（SQLインジェクション、APIバリデーション等）との比較を用いる。
- **文体**: 既存のWeek 1〜3前半の記事に合わせて、「です・ます」調を基本とすること。
- **正確性**: 技術的に正確かつ、読者が実際に手を動かして学べる実践的な内容にすること。
- **連続性**: 連載記事であるため、既存記事の流れを崩さないこと。特に以下の記事からの続きであることを意識する。
    - `week3-01-observability-langfuse.md`（観測性）
    - `week3-02-evaluation-prompt-management.md`（評価・プロンプト管理）
- **ファイル名**: コードブロックには必ずファイル名（例: `server.py`, `evaluate.py`）を明記すること。
- **実行可能性**: 記事内のコードは実際に動作するものであること。必要に応じて `requirements.txt` への追記を指示する。
- **Langfuseとの連携**: 第6章・第7章で導入したLangfuseを活用し、変更の効果を可視化する方法を示すこと。
